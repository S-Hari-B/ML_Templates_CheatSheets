{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBKu9DLxWY0K"
   },
   "source": [
    "## Loading in dataset for checking templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DyPeTOMfWPnr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the dataset\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1BPAyBRXaEI",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocessing for model - refer to preprocessing template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7k8jMru4XWii"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def impute_missing_values(df, strategy='mean', fill_value=None, columns=None):\n",
    "\n",
    "  if columns is None:\n",
    "    columns = df.columns # The imputer is applied to all columns in the dataset\n",
    "\n",
    "  imputer = SimpleImputer(strategy=strategy, fill_value=fill_value) # Initializing the imputer\n",
    "  df[columns] = imputer.fit_transform(df[columns]) # Applying the imputer to selected columns\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def encode_categorical(df, columns, method='onehot'):\n",
    "\n",
    "    if method == 'onehot':\n",
    "        for col in columns:\n",
    "            encoder = OneHotEncoder(sparse_output=False, drop='first') # Converting the spare matrix which is outputted by default into a dense array. Drop first to avoid multicolinearity which undermines the statistical significance of an independent variable\n",
    "            encoded = encoder.fit_transform(df[[col]]) # The encoded column\n",
    "            encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([col]), index=df.index)\n",
    "            df = pd.concat([df, encoded_df], axis=1) # Appending the encoded columns to the df\n",
    "            df.drop(columns=col, inplace=True) # Dropping the original columns\n",
    "\n",
    "    elif method == 'label':\n",
    "        for col in columns:\n",
    "            encoder = LabelEncoder()\n",
    "            df[col] = encoder.fit_transform(df[col]) # Replacing the original columns with the label encoded values\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_low_correlation_features(df, target_column, threshold=0.1):\n",
    "\n",
    "    df = df.select_dtypes(include=['number']) # Filtering numeric columns only\n",
    "\n",
    "    corr_with_target = df.corr()[target_column].abs() # Absolute correlation with the target\n",
    "    low_corr_features = corr_with_target[corr_with_target < threshold].index.tolist()\n",
    "\n",
    "    print(f'Features to drop (correlation with {target_column} < {threshold}): {low_corr_features}')\n",
    "    return df.drop(columns=low_corr_features), corr_with_target\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "def scale_data(df, scaler_type=\"standard\", columns=None):\n",
    "\n",
    "  scalers = {\n",
    "      'standard': StandardScaler(),\n",
    "      'minmax': MinMaxScaler(),\n",
    "      'robust': RobustScaler()\n",
    "  }\n",
    "  scaler = scalers.get(scaler_type)\n",
    "\n",
    "\n",
    "  if columns is None:\n",
    "    columns = df.select_dtypes(include=['number']).columns # Default to numeric columns if no specific columns are provided\n",
    "\n",
    "\n",
    "  scaled_df = pd.DataFrame(scaler.fit_transform(df[columns]), columns=columns)\n",
    "\n",
    "\n",
    "  return scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYfq2ynjYATX",
    "outputId": "9ab45ef7-5e08-4c1d-8fbe-476c9f5232b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to drop (correlation with survived < 0.1): ['age', 'sibsp', 'parch']\n",
      "\n",
      "Scaled X Values\n",
      "      pclass      fare     class  sex_male  adult_male_True   who_man  \\\n",
      "0  0.827377 -0.502445  0.827377  0.737695         0.811922  0.811922   \n",
      "1 -1.566107  0.786845 -1.566107 -1.355574        -1.231645 -1.231645   \n",
      "2  0.827377 -0.488854  0.827377 -1.355574        -1.231645 -1.231645   \n",
      "3 -1.566107  0.420730 -1.566107 -1.355574        -1.231645 -1.231645   \n",
      "4  0.827377 -0.486337  0.827377  0.737695         0.811922  0.811922   \n",
      "\n",
      "   who_woman  alone_True  \n",
      "0  -0.661133   -1.231645  \n",
      "1   1.512555   -1.231645  \n",
      "2   1.512555    0.811922  \n",
      "3   1.512555   -1.231645  \n",
      "4  -0.661133    0.811922  \n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['embarked', 'embark_town', 'deck', 'alive'], axis=1)\n",
    "df = impute_missing_values(df, strategy=\"mean\", columns=['age'])\n",
    "df = encode_categorical(df, columns=['sex', 'adult_male', 'who', 'alone'], method='onehot')\n",
    "df = encode_categorical(df, columns=['class'], method='label')\n",
    "df, corr_with_target = remove_low_correlation_features(df, target_column='survived', threshold=0.1)\n",
    "X = df.drop(columns=['survived'], axis=1)\n",
    "y = df['survived']\n",
    "X = scale_data(X)\n",
    "print('\\nScaled X Values\\n', X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2wr6A_FZprW"
   },
   "source": [
    "## Single Model + HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gn52zIf1Zcqe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, r2_score\n",
    "\n",
    "def single_model_hpt(X, y, model, param_grid, search_type='random', model_type='class', cv=3):\n",
    "  '''\n",
    "  Performs hyperparameter tuning for a single classification or regression model using either grid or random search.\n",
    "\n",
    "  Parameters:\n",
    "    X: Pandas df or numpy array of the features\n",
    "    y: Pandas df or numpy array of the target\n",
    "    model: The initialized model\n",
    "    param_grid: A dictionary of hyperparameters to tune for the model\n",
    "    search_type: Type-str, Default-random, Options - grid, random. The type of search to be carried out on the hyperparams\n",
    "    model_type: Tpe-str, Default-class, Options - class, reg. Whether the model type is a classification or regression model\n",
    "    cv: Type-int, Default-3. The number of cross validation folds. Can change after doing k fold cv, might incorporate in later.\n",
    "\n",
    "  Returns:\n",
    "    best_model: The tuned model with the best hyperparams\n",
    "    best_params: A dictionary of the chosen best hyperparams\n",
    "    best_score: A float of the best cross-validation score\n",
    "  '''\n",
    "\n",
    "  # Splitting into the train_test_split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Selecting the search method\n",
    "  if search_type == 'random':\n",
    "    search = RandomizedSearchCV(model, param_grid, cv=cv, scoring='accuracy' if model_type == 'class' else 'neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "  elif search_type == 'grid':\n",
    "    search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy' if model_type == 'class' else 'neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "  # Fitting the search to the features\n",
    "  search.fit(X_train, y_train)\n",
    "\n",
    "  # Results of the search\n",
    "  best_model = search.best_estimator_\n",
    "  best_params = search.best_params_\n",
    "  best_score = search.best_score_\n",
    "\n",
    "  print(\"Best Parameters:\", best_params)\n",
    "  print(\"Best Cross-Validation Score:\", best_score)\n",
    "\n",
    "  # Test set evaluation\n",
    "  y_pred = best_model.predict(X_test)\n",
    "\n",
    "  # Evaluation Metrics\n",
    "\n",
    "  # Classification Evaluation\n",
    "  if model_type == 'class':\n",
    "    print(\"\\nTest Set Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "  # Regression evaluation\n",
    "  elif model_type == 'reg':\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"\\nTest Set Regression Metrics:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "\n",
    "  return best_model, best_params, best_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiniAi_juVmg"
   },
   "source": [
    "### Testing the single model hpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wz2JWAFPuYZn",
    "outputId": "b7743036-2923-491d-ed66-ffb7bb8e67fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 10}\n",
      "Best Cross-Validation Score: 0.8160302095521753\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       105\n",
      "           1       0.80      0.76      0.78        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Model and parameter grid\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'max_depth': [2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "best_model, best_params, best_score = single_model_hpt(X, y, model, param_grid, search_type=\"random\", model_type=\"class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpsbyIaauidP",
    "outputId": "7786474f-347b-4389-921a-f49bb686984c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8212290502793296\n"
     ]
    }
   ],
   "source": [
    "# Splitting into the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_QSFD0ywaDe"
   },
   "source": [
    "## Multi Model Comparision + HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "48x9T2i0weWW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, r2_score\n",
    "\n",
    "def compare_models_hpt(X, y, models, search_type='random', model_type='class', cv=3):\n",
    "  '''\n",
    "  Performs hyperparameter tuning on multiple models and selects the best one with tuned hp's.\n",
    "\n",
    "  Parameters:\n",
    "    X: Pandas df or numpy array of the features\n",
    "    y: Pandas df or numpy array of the target\n",
    "    model: Type-dict, A dict where the keys are the model names and the values are tuples with the params to tune (model, param_grid)\n",
    "    search_type: Type-str, Default-random, Options - grid, random. The type of search to be carried out on the hyperparams\n",
    "    model_type: Type-str, Default-class, Options - class, reg. Whether the model type is a classification or regression model\n",
    "    cv: Type-int, Default-3. The number of cross validation folds. Can change after doing k fold cv, might incorporate in later.\n",
    "\n",
    "  Returns:\n",
    "    best_model: The tuned model with the best hyperparams\n",
    "    best_params: A dictionary of the chosen best hyperparams\n",
    "    best_score: A float of the best cross-validation score\n",
    "  '''\n",
    "\n",
    "  # Splitting into the train_test_split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "  results = [] # Empty list to the store the results of each model\n",
    "\n",
    "  for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Running hyperparameter tuning for {model_name}...\")\n",
    "\n",
    "    # Selecting search method\n",
    "    if search_type == 'random':\n",
    "      search = RandomizedSearchCV(model, param_grid, cv=cv, scoring='accuracy' if model_type == 'class' else 'neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "    elif search_type == 'grid':\n",
    "      search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy' if model_type == 'class' else 'neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fitting the search\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # Getting the results for this model\n",
    "    best_model = search.best_estimator_\n",
    "    best_params = search.best_params_\n",
    "    best_score = search.best_score_\n",
    "\n",
    "    print(f\"Best Parameters for {model_name}: {best_params}\")\n",
    "    print(f\"Best Cross-Validation Score for {model_name}: {best_score}\")\n",
    "\n",
    "    # Appending the results to the empty list\n",
    "    results.append((model_name, best_model, best_params, best_score))\n",
    "\n",
    "  # Finding the best model based on the scores\n",
    "  best_model_name, best_model, best_params, best_score = max(results, key=lambda x: x[3]) # Sorting by the score values\n",
    "\n",
    "  print(f\"\\nBest Model: {best_model_name}\")\n",
    "  print(f\"Best Parameters: {best_params}\")\n",
    "  print(f\"Best Cross-Validation Score: {best_score}\")\n",
    "\n",
    "  # Test set evaluation for the best model\n",
    "  y_pred = best_model.predict(X_test)\n",
    "\n",
    "  if model_type == 'class':\n",
    "    print(\"\\nTest Set Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "  elif model_type == 'reg':\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"\\nTest Set Regression Metrics:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "\n",
    "  return best_model, best_model_name, best_params, best_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzbiVL8i0Enr"
   },
   "source": [
    "### Testing the multi model on classification and regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "j3k69tfX0QM7",
    "outputId": "1d102fb8-a173-44c4-85cb-c037583ec537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hyperparameter tuning for DecisionTree...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Best Parameters for DecisionTree: {'max_depth': 4, 'min_samples_split': 2}\n",
      "Best Cross-Validation Score for DecisionTree: 0.8174484983866964\n",
      "Running hyperparameter tuning for RandomForest...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Best Parameters for RandomForest: {'max_depth': 10, 'n_estimators': 50}\n",
      "Best Cross-Validation Score for RandomForest: 0.7921261331536834\n",
      "\n",
      "Best Model: DecisionTree\n",
      "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
      "Best Cross-Validation Score: 0.8174484983866964\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       105\n",
      "           1       0.81      0.74      0.77        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis example is a classification one so regression test not needed but here as an example.\\n\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n# Define models and parameter grids\\nmodels = {\\n    \\'LinearRegression\\': (\\n        LinearRegression(),\\n        {}\\n    ),\\n    \\'RandomForestRegressor\\': (\\n        RandomForestRegressor(random_state=42),\\n        {\\'n_estimators\\': [50, 100, 200], \\'max_depth\\': [None, 10, 20]}\\n    )\\n}\\n\\n# Comparing the regression models and select the best one\\nbest_model, best_model_name, best_params, best_score = compare_models_hpt(X, y, models, search_type=\"random\", model_type=\"reg\", cv=3)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Defining the models and parameter grids\n",
    "models = {\n",
    "    'DecisionTree': (\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        {'max_depth': [2, 4, 6, 8, 10], 'min_samples_split': [2, 5, 10]}\n",
    "    ),\n",
    "    'RandomForest': (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}\n",
    "    )\n",
    "}\n",
    "\n",
    "# Comparing the classification models and select the best one\n",
    "best_model, best_model_name, best_params, best_score = compare_models_hpt(X, y, models, search_type=\"grid\", model_type=\"class\", cv=3)\n",
    "\n",
    "\n",
    "'''\n",
    "This example is a classification one so regression test not needed but here as an example.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define models and parameter grids\n",
    "models = {\n",
    "    'LinearRegression': (\n",
    "        LinearRegression(),\n",
    "        {}\n",
    "    ),\n",
    "    'RandomForestRegressor': (\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
    "    )\n",
    "}\n",
    "\n",
    "# Comparing the regression models and select the best one\n",
    "best_model, best_model_name, best_params, best_score = compare_models_hpt(X, y, models, search_type=\"random\", model_type=\"reg\", cv=3)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBapQRof2wxz",
    "outputId": "7991d44c-b996-4d1d-823c-71402c6dd765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8212290502793296\n"
     ]
    }
   ],
   "source": [
    "# Splitting into the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ewuSbs_3Kpa"
   },
   "source": [
    "## Stacked Model - No HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dbfXB92R3R0S"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, mean_absolute_error, r2_score\n",
    "\n",
    "def stacked_model(X, y, base_models, meta_model, model_type='class', n_folds=3):\n",
    "  '''\n",
    "  Stacks multiple base models with a meta-model for the final prediction.\n",
    "\n",
    "  Parameters:\n",
    "    X: Pandas df or numpy array of the features\n",
    "    y: Pandas df or numpy array of the target\n",
    "    base_models: Type-list, The list of the base models to be stacked and trained\n",
    "    meta_model: The model used for the final prediction. Takes the predicted data from the base_models and estimates on that\n",
    "    model_type: Type-str, Default-class, Options - class, reg. Whether the model type is a classification or regression model\n",
    "    n_folds: Type-int, Default-3, The number of cross validation folds - Can tune later\n",
    "\n",
    "  Returns:\n",
    "    meta_model: The trained meta model\n",
    "    base_model_preds: Predictions from base models (Level 1 data)\n",
    "    final_score: The final score given from the test set\n",
    "  '''\n",
    "\n",
    "  # Ensuring X and y are NumPy arrays\n",
    "  X = np.array(X)\n",
    "  y = np.array(y)\n",
    "\n",
    "  # k-fold cross validation\n",
    "  kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "  # An array of zeros made to store the predictions from each of the base models\n",
    "  base_model_preds = np.zeros((X.shape[0], len(base_models)))\n",
    "\n",
    "  # Training each base model using the K-Fold CV\n",
    "  for i, model in enumerate(base_models):\n",
    "    print(f\"Training base model {i+1}: {model.__class__.__name__}\")\n",
    "    fold_preds = np.zeros(X.shape[0]) # Storing the model's predictions for this fold\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "      X_train, X_val = X[train_idx], X[val_idx]\n",
    "      y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "      model.fit(X_train, y_train)\n",
    "      fold_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    base_model_preds[:, i] = fold_preds # Storing predictions for this model\n",
    "\n",
    "  # Training the meta-model on the predictions of base models (Level 1 data)\n",
    "  if model_type == 'class':\n",
    "    meta_model.fit(base_model_preds, y)\n",
    "    meta_preds = meta_model.predict(base_model_preds)\n",
    "    final_score = classification_report(y, meta_preds)\n",
    "    print(f\"\\nFinal Meta-Model Accuracy:\\n {final_score}\")\n",
    "\n",
    "  elif model_type == 'reg':\n",
    "    meta_model.fit(base_model_preds, y)\n",
    "    meta_preds = meta_model.predict(base_model_preds)\n",
    "    mae = mean_absolute_error(y, meta_preds)\n",
    "    r2 = r2_score(y, meta_preds)\n",
    "    final_score = {\"MAE\": mae, \"R2\": r2}\n",
    "    print(f\"\\nFinal Meta-Model Regression Metrics:\\n {final_score}\")\n",
    "\n",
    "  return meta_model, base_model_preds, final_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3NAhAtIldPe"
   },
   "source": [
    "### Testing the stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "E8N71545lfYe",
    "outputId": "9a44667b-dcc0-44df-e461-2155cd8a327f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base model 1: DecisionTreeClassifier\n",
      "Training base model 2: RandomForestClassifier\n",
      "\n",
      "Final Meta-Model Accuracy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       549\n",
      "           1       0.83      0.69      0.75       342\n",
      "\n",
      "    accuracy                           0.83       891\n",
      "   macro avg       0.83      0.80      0.81       891\n",
      "weighted avg       0.83      0.83      0.82       891\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThis example is a classification one so regression test not needed but here as an example.\\n\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.ensemble import RandomForestRegressor\\n\\n# Feature matrix and target\\nX = df.drop(columns=['target_column']).values\\ny = df['target_column'].values\\n\\n# Base models\\nbase_models = [\\n    LinearRegression(),\\n    RandomForestRegressor(n_estimators=100, random_state=42)\\n]\\n\\n# Meta-model\\nmeta_model = RandomForestRegressor(n_estimators=50, random_state=42)\\n\\n# Perform stacking\\nmeta_model, base_model_preds, final_score = stacked_model(X, y, base_models, meta_model, model_type='reg', n_folds=3)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "]\n",
    "\n",
    "# Meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Performing stacking\n",
    "meta_model, base_model_preds, final_score = stacked_model(X, y, base_models, meta_model, model_type='class', n_folds=3)\n",
    "\n",
    "\n",
    "'''\n",
    "This example is a classification one so regression test not needed but here as an example.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Feature matrix and target\n",
    "X = df.drop(columns=['target_column']).values\n",
    "y = df['target_column'].values\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "]\n",
    "\n",
    "# Meta-model\n",
    "meta_model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "\n",
    "# Perform stacking\n",
    "meta_model, base_model_preds, final_score = stacked_model(X, y, base_models, meta_model, model_type='reg', n_folds=3)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQ--I64Bl4G3",
    "outputId": "63974347-b83c-4bd9-f516-25ca35588491"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting into the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Generating predictions from base models for the test set\n",
    "base_model_preds_test = np.zeros((X_test.shape[0], len(base_models)))\n",
    "\n",
    "for i, model in enumerate(base_models):\n",
    "    base_model_preds_test[:, i] = model.predict(X_test)\n",
    "\n",
    "# Make final predictions using the meta-model\n",
    "y_test_pred = meta_model.predict(base_model_preds_test)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kHM4LUU0iOc"
   },
   "source": [
    "## Voting Model - No HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Mf_xwfGJnR39"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, VotingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, classification_report\n",
    "\n",
    "def voting_model(X, y, models, model_type='class', voting='soft'):\n",
    "  '''\n",
    "  A voting ensemble model which combines multiple models and uses a majority vote (for classification) or an average (for regression) to make predictions.\n",
    "\n",
    "  Parameters:\n",
    "    X: Pandas df or numpy array of the features\n",
    "    y: Pandas df or numpy array of the target\n",
    "    models: Type-list of tuples, A list of the (name, model) tuples that will vote\n",
    "    model_type: Type-str, Default-class, Options - class, reg. Whether the model type is a classification or regression model\n",
    "    voting: Type-str, Default-soft, Options - Soft or Hard Voting style. Soft is for classification only, both can use Hard but classification defaults to soft\n",
    "\n",
    "  Info:\n",
    "    Hard Voting: Each model predicts a class (for classification tasks), and the final prediction is the class with the majority vote\n",
    "    Soft Voting: Instead of predicting classes directly, models output probabilities for each class. The final prediction is based on the average probability across models\n",
    "\n",
    "  Returns:\n",
    "    model: The trained voting model\n",
    "    Evaluation metrics: Experimenting having the function return the eval metrics - might remove out\n",
    "  '''\n",
    "\n",
    "  # Train test split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Creating the voting model\n",
    "  if model_type == 'class':\n",
    "    model = VotingClassifier(estimators=models, voting=voting, n_jobs=-1)\n",
    "  elif model_type == 'reg':\n",
    "    model = VotingRegressor(estimators=models, n_jobs=-1)\n",
    "\n",
    "  # Training the model\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Predicting and evaluating\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  if model_type == 'class':\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    return model, {\"Accuracy\": accuracy}\n",
    "\n",
    "  elif model_type == 'reg':\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Error: {mae}, R2 Score: {r2}\")\n",
    "    return model, {\"MAE\": mae, \"R2\": r2}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmu0_K0A4QTC"
   },
   "source": [
    "### Testing the voting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TL_ZClf4LJD",
    "outputId": "7cf3cea3-d5f2-42a4-ad2d-c74d4c81cd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       105\n",
      "           1       0.86      0.73      0.79        74\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.84      0.82      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define estimators\n",
    "models = [\n",
    "    ('DecisionTree', DecisionTreeClassifier(max_depth=5, random_state=42)),\n",
    "    ('RandomForest', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('LogisticRegression', LogisticRegression())\n",
    "]\n",
    "\n",
    "# Train and evaluate VotingClassifier\n",
    "voting_model, metrics = voting_model(X, y, models, model_type='class', voting='soft')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcZu_8Nu42l5"
   },
   "source": [
    "## Bagging Model - No HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BJ00mw8G40th"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, classification_report\n",
    "\n",
    "def bagging_model(X, y, base_model, model_type='class', n_estimators=10, max_samples=0.8):\n",
    "  '''\n",
    "  Bagging model to improve a models performance by training the same base model on different random subsets of the data.\n",
    "\n",
    "  Parameters:\n",
    "    X: Pandas df or numpy array of the features\n",
    "    y: Pandas df or numpy array of the target\n",
    "    base_model: The model that will be bagged and improved\n",
    "    model_type: Type-str, Default-class, Options - class, reg. Whether the model type is a classification or regression model\n",
    "    n-estimators: Type-int, Default-10, The number of base estimators\n",
    "    max_samples: Type-int, Default-0.8, The fraction of samples for each estimator\n",
    "\n",
    "  Returns:\n",
    "    model: The trained bagging model\n",
    "    Evaluation metrics: Experimenting having the function return the eval metrics - might remove out\n",
    "  '''\n",
    "\n",
    "  # Train test split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Creating the bagging model\n",
    "  if model_type == 'class':\n",
    "    model = BaggingClassifier(base_model, n_estimators=n_estimators, max_samples=max_samples, random_state=42)\n",
    "  elif model_type == 'reg':\n",
    "    model = BaggingRegressor(base_model, n_estimators=n_estimators, max_samples=max_samples, random_state=42)\n",
    "\n",
    "  # Training the model\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Predicting and evaluating\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  if model_type == 'class':\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    return model, {\"Accuracy\": accuracy}\n",
    "\n",
    "  elif model_type == 'reg':\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Error: {mae}, R2 Score: {r2}\")\n",
    "    return model, {\"MAE\": mae, \"R2\": r2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CI-05O59XPG"
   },
   "source": [
    "### Testing the bagging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FZ7SZYp9ZEk",
    "outputId": "7c3a4af3-ff11-4e88-e375-988e46f27262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       105\n",
      "           1       0.81      0.74      0.77        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Example for BaggingClassifier\n",
    "bagging_model, metrics = bagging_model(X, y, base_model=DecisionTreeClassifier(), model_type='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdxMMeoo9l29"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "tBKu9DLxWY0K",
    "Y1BPAyBRXaEI",
    "M2wr6A_FZprW",
    "h_QSFD0ywaDe",
    "_ewuSbs_3Kpa",
    "2kHM4LUU0iOc",
    "RcZu_8Nu42l5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
